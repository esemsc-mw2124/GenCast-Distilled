{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57565c5e",
   "metadata": {},
   "source": [
    "> Adapted from DeepMind Technologies Limited code under Apache 2.0.\n",
    ">\n",
    "> Specifically, this is based on the provided demo notebook available at the following [link](https://github.com/google-deepmind/graphcast/blob/main/gencast_mini_demo.ipynb).\n",
    ">\n",
    "> This code is distributed under the same license."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba46bc",
   "metadata": {},
   "source": [
    "# Distilled GenCast inference and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964e0a7",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642cb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import xarray\n",
    "import numpy as np\n",
    "import gcsfs\n",
    "import jax\n",
    "import io\n",
    "import copy\n",
    "from IPython import display\n",
    "\n",
    "import gencast_distillation.config as config\n",
    "from inference_helpers import init_and_compile\n",
    "from plotting_helpers import select, scale, plot_data\n",
    "from eval_helpers import evaluate\n",
    "from graphcast import checkpoint\n",
    "from graphcast import gencast\n",
    "from graphcast import data_utils\n",
    "from graphcast import rollout\n",
    "from graphcast import xarray_jax\n",
    "from graphcast import normalization\n",
    "from graphcast import nan_cleaning\n",
    "from graphcast import xarray_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7e480",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedd6d1a",
   "metadata": {},
   "source": [
    "## Load data and initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537f4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_base = \"gs://gencast-distillation-bucket\"\n",
    "fs = gcsfs.GCSFileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122c28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = f\"{bucket_base}/gencast_weights/gencast_params_GenCast 1p0deg Mini _2019.npz\"\n",
    "with fs.open(weights_path, 'rb') as f:\n",
    "    model_weights = io.BytesIO(f.read())\n",
    "\n",
    "teacher_ckpt = checkpoint.load(model_weights, gencast.CheckPoint)\n",
    "params = teacher_ckpt.params\n",
    "state = {}\n",
    "\n",
    "task_config = teacher_ckpt.task_config\n",
    "sampler_config = teacher_ckpt.sampler_config\n",
    "noise_config = teacher_ckpt.noise_config\n",
    "noise_encoder_config = teacher_ckpt.noise_encoder_config\n",
    "denoiser_architecture_config = teacher_ckpt.denoiser_architecture_config\n",
    "\n",
    "print(task_config)\n",
    "print(\"===\")\n",
    "print(sampler_config) # where we should see changes\n",
    "print(\"===\")\n",
    "print(noise_config)\n",
    "print(\"===\")\n",
    "print(noise_encoder_config)\n",
    "print(\"===\")\n",
    "print(denoiser_architecture_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095546d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teacher_ckpt.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589e6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../student_ckpt.pkl\", \"rb\") as f:\n",
    "    student_params = pickle.load(f)\n",
    "\n",
    "print(student_params)\n",
    "\n",
    "# student_ckpt = copy.deepcopy(teacher_ckpt)\n",
    "# # student_ckpt.params = student_params\n",
    "# student_ckpt.sampler_config.num_noise_levels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c049d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_data =  config.example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9010d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_targets, train_forcings = data_utils.extract_inputs_targets_forcings(\n",
    "    era5_data, target_lead_times=slice(\"12h\", \"12h\"), # Only 1AR training.\n",
    "    **dataclasses.asdict(task_config))\n",
    "\n",
    "eval_inputs, eval_targets, eval_forcings = data_utils.extract_inputs_targets_forcings(\n",
    "    era5_data, target_lead_times=slice(\"12h\", f\"{(era5_data.dims['time']-2)*12}h\"), # All but 2 input frames.\n",
    "    **dataclasses.asdict(task_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de41595",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = config.normalization_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c021b",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: move to helper\n",
    "\n",
    "# def construct_wrapped_gencast():\n",
    "#   \"\"\"Constructs and wraps the GenCast Predictor.\"\"\"\n",
    "#   predictor = gencast.GenCast(\n",
    "#       sampler_config=sampler_config,\n",
    "#       task_config=task_config,\n",
    "#       denoiser_architecture_config=denoiser_architecture_config,\n",
    "#       noise_config=noise_config,\n",
    "#       noise_encoder_config=noise_encoder_config,\n",
    "#   )\n",
    "\n",
    "#   predictor = normalization.InputsAndResiduals(\n",
    "#       predictor,\n",
    "#       diffs_stddev_by_level=norm_data[\"diffs_stddev_by_level\"],\n",
    "#       mean_by_level=norm_data[\"mean_by_level\"],\n",
    "#       stddev_by_level=norm_data[\"stddev_by_level\"],\n",
    "#   )\n",
    "\n",
    "#   predictor = nan_cleaning.NaNCleaner(\n",
    "#       predictor=predictor,\n",
    "#       reintroduce_nans=True,\n",
    "#       fill_value=norm_data[\"min_by_level\"],\n",
    "#       var_to_clean='sea_surface_temperature',\n",
    "#   )\n",
    "\n",
    "#   return predictor\n",
    "\n",
    "\n",
    "# @hk.transform_with_state\n",
    "# def run_forward(inputs, targets_template, forcings):\n",
    "#   predictor = construct_wrapped_gencast()\n",
    "#   return predictor(inputs, targets_template=targets_template, forcings=forcings)\n",
    "\n",
    "\n",
    "# @hk.transform_with_state\n",
    "# def loss_fn(inputs, targets, forcings):\n",
    "#   predictor = construct_wrapped_gencast()\n",
    "#   loss, diagnostics = predictor.loss(inputs, targets, forcings)\n",
    "#   return xarray_tree.map_structure(\n",
    "#       lambda x: xarray_jax.unwrap_data(x.mean(), require_jax=True),\n",
    "#       (loss, diagnostics),\n",
    "#   )\n",
    "\n",
    "\n",
    "# if params is None:\n",
    "#   init_jitted = jax.jit(loss_fn.init)\n",
    "#   params, state = init_jitted(\n",
    "#       rng=jax.random.PRNGKey(0),\n",
    "#       inputs=train_inputs,\n",
    "#       targets=train_targets,\n",
    "#       forcings=train_forcings,\n",
    "#   )\n",
    "\n",
    "# run_forward_jitted = jax.jit(\n",
    "#     lambda rng, i, t, f: run_forward.apply(params, state, rng, i, t, f)[0]\n",
    "# )\n",
    "# # We also produce a pmapped version for running in parallel.\n",
    "# run_forward_pmap = xarray_jax.pmap(run_forward_jitted, dim=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf220bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of ensemble members should be a multiple of the number of devices.\n",
    "# This should be adapted in the next cell\n",
    "print(f\"Number of local devices {len(jax.local_devices())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, state, run_forward_jitted, run_forward_pmap = init_and_compile(\n",
    "    rng_key=jax.random.PRNGKey(0),\n",
    "    sampler_config=sampler_config,\n",
    "    task_config=task_config,\n",
    "    denoiser_architecture_config=denoiser_architecture_config,\n",
    "    noise_config=noise_config,\n",
    "    noise_encoder_config=noise_encoder_config,\n",
    "    norm_data=norm_data,\n",
    "    train_inputs=train_inputs,\n",
    "    train_targets=train_targets,\n",
    "    train_forcings=train_forcings,\n",
    ")\n",
    "\n",
    "\n",
    "num_ensemble_members = 40\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rngs = np.stack(\n",
    "    [jax.random.fold_in(rng, i) for i in range(num_ensemble_members)], axis=0)\n",
    "\n",
    "chunks = []\n",
    "for chunk in rollout.chunked_prediction_generator_multiple_runs(\n",
    "    # Use pmapped version to parallelise across devices.\n",
    "    predictor_fn=run_forward_pmap,\n",
    "    rngs=rngs,\n",
    "    inputs=eval_inputs,\n",
    "    targets_template=eval_targets * np.nan,\n",
    "    forcings=eval_forcings,\n",
    "    num_steps_per_chunk = 1,\n",
    "    num_samples = num_ensemble_members,\n",
    "    pmap_devices=jax.local_devices()\n",
    "    ):\n",
    "    chunks.append(chunk)\n",
    "    \n",
    "predictions = xarray.combine_by_coords(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275c638",
   "metadata": {},
   "source": [
    "## Plot predictions\n",
    "\n",
    "Here we plot the predictions for `2m_temperature`, which is the air temperature at 2 meters above the surface. Note that this can be substituted with any variable we predict, and the corresponding pressure level where applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669cf397",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size = 5\n",
    "plot_max_steps = predictions.dims[\"time\"]\n",
    "level = predictions.coords['level'].values[0]\n",
    "\n",
    "fig_title = \"2m_temperature\"\n",
    "if \"level\" in predictions[\"2m_temperature\"].coords:\n",
    "  fig_title += f\" at {level} hPa\"\n",
    "\n",
    "for sample_idx in range(min(4, num_ensemble_members)):\n",
    "  data = {\n",
    "      \"Targets\": scale(select(eval_targets, \"2m_temperature\", level, plot_max_steps), robust=True),\n",
    "      \"Predictions\": scale(select(predictions.isel(sample=sample_idx), \"2m_temperature\", level, plot_max_steps), robust=True),\n",
    "      \"Diff\": scale((select(eval_targets, \"2m_temperature\", level, plot_max_steps) -\n",
    "                          select(predictions.isel(sample=sample_idx), \"2m_temperature\", level, plot_max_steps)),\n",
    "                        robust=True, center=0),\n",
    "  }\n",
    "  display.display(plot_data(data, fig_title + f\", Sample {sample_idx}\", plot_size, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1debbb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps(targets, predictions, bias_corrected = True):\n",
    "  if predictions.sizes.get(\"sample\", 1) < 2:\n",
    "    raise ValueError(\n",
    "        \"predictions must have dim 'sample' with size at least 2.\")\n",
    "  sum_dims = [\"sample\", \"sample2\"]\n",
    "  preds2 = predictions.rename({\"sample\": \"sample2\"})\n",
    "  num_samps = predictions.sizes[\"sample\"]\n",
    "  num_samps2 = (num_samps - 1) if bias_corrected else num_samps\n",
    "  mean_abs_diff = np.abs(\n",
    "      predictions - preds2).sum(\n",
    "          dim=sum_dims, skipna=False) / (num_samps * num_samps2)\n",
    "  mean_abs_err = np.abs(targets - predictions).sum(dim=\"sample\", skipna=False) / num_samps\n",
    "  return mean_abs_err - 0.5 * mean_abs_diff\n",
    "\n",
    "\n",
    "plot_size = 5\n",
    "plot_max_steps = predictions.dims[\"time\"]\n",
    "level = predictions.coords['level'].values[0]\n",
    "\n",
    "fig_title = \"2m_temperature\"\n",
    "if \"level\" in predictions[\"2m_temperature\"].coords:\n",
    "  fig_title += f\" at {level} hPa\"\n",
    "\n",
    "data = {\n",
    "    \"Targets\": scale(select(eval_targets, \"2m_temperature\", level, plot_max_steps), robust=True),\n",
    "    \"Ensemble Mean\": scale(select(predictions.mean(dim=[\"sample\"]), \"2m_temperature\", level, plot_max_steps), robust=True),\n",
    "    \"Ensemble CRPS\": scale(crps((select(eval_targets, \"2m_temperature\", level, plot_max_steps)),\n",
    "                        select(predictions, \"2m_temperature\", level, plot_max_steps)),\n",
    "                      robust=True, center=0),\n",
    "}\n",
    "display.display(plot_data(data, fig_title, plot_size, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(predictions, eval_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
